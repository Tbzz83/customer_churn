{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "16o8__ChU1-W"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from imblearn.over_sampling import RandomOverSampler\n",
        "import seaborn as sns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZvvVrw04VGbK"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv(\"customer_data.csv\")\n",
        "\n",
        "for col in df.columns:\n",
        "  df.loc[df[col]== ' ', col] = 0\n",
        "# For some reason, there are some blank strings in some columns, which should be 0 values\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OAxeVdjSIHKP"
      },
      "source": [
        "# Cleaning data, converting categorical to one-hot encoded columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wl6ZFsW8WA1h"
      },
      "outputs": [],
      "source": [
        "\n",
        "df['gender'] = (df['gender'] == \"Male\").astype(int)\n",
        "df['InternetService'] = (df['InternetService'] == \"DSL\").astype(int)\n",
        "df['Contract'] = (df['Contract'] == \"Month-to-month\").astype(int)\n",
        "df['TotalCharges'] = df['TotalCharges'].astype(float)\n",
        "\n",
        "\n",
        "# Getting dummy cols from cols with more than two possible categorical values\n",
        "multiple_lines_encoded = pd.get_dummies(df['MultipleLines'], prefix='MultipleLines')\n",
        "df = pd.concat([df, multiple_lines_encoded], axis=1)\n",
        "\n",
        "payment_method_encoded = pd.get_dummies(df['PaymentMethod'], prefix='PaymentMethod')\n",
        "df = pd.concat([df, payment_method_encoded], axis=1)\n",
        "\n",
        "df.drop(columns = ['customerID', 'MultipleLines', 'PaymentMethod'], inplace = True)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BYejxtTVGE25"
      },
      "outputs": [],
      "source": [
        "# Yes and no converted to binary\n",
        "yes_to_int = ['Partner', 'Dependents', 'PhoneService', 'OnlineSecurity', 'OnlineBackup', 'DeviceProtection', 'TechSupport', 'StreamingTV', 'StreamingMovies', 'PaperlessBilling', 'Churn']\n",
        "for label in yes_to_int:\n",
        "  df[label] = (df[label] == 'Yes').astype(int)\n",
        "\n",
        "# True or false converted to binary\n",
        "t_f_to_int = ['MultipleLines_No', 'MultipleLines_No phone service', 'MultipleLines_Yes', 'PaymentMethod_Bank transfer (automatic)', 'PaymentMethod_Credit card (automatic)',\n",
        "              'PaymentMethod_Electronic check', 'PaymentMethod_Mailed check']\n",
        "for label in t_f_to_int:\n",
        " df[label] = (df[label] == True).astype(int)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XZxQuNbEIMv_"
      },
      "source": [
        "# Visualizing features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8-kyjRt4v3dE"
      },
      "outputs": [],
      "source": [
        "#for label in df.drop('Churn', axis=1).columns:\n",
        "#  plt.hist(df[df[\"Churn\"] == 1][label], color=\"blue\", label = 'Churned', alpha = 0.7, density=True)\n",
        "#  plt.hist(df[df[\"Churn\"] == 0][label], color=\"red\", label = 'Not churned', alpha = 0.7, density=True)\n",
        "#  plt.title(label)\n",
        "#  plt.ylabel('Probability')\n",
        "#  plt.xlabel(label)\n",
        "#  plt.legend()\n",
        "#  plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qR5SrMTYc3Qt"
      },
      "outputs": [],
      "source": [
        "# Based on these visualizations, we can drop some columns that don't appear to have a strong association\n",
        "df.drop(columns = ['gender', 'PhoneService', 'MultipleLines_No', 'MultipleLines_No phone service'], inplace = True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aECi36EiMieL"
      },
      "source": [
        "# Train, validation, test datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Lh5-HJSWLk_i"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import classification_report"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OvSX2m0cyBcm"
      },
      "outputs": [],
      "source": [
        "# We need to scale the dataset but only for features that are not binary\n",
        "# In our case thats tenure, MonthlyCharges, and TotalCharges\n",
        "# In the scaling function below, we include a case where we can pass in columns to ignore\n",
        "\n",
        "def selectively_scale_dataset(dataset, binary_cols):\n",
        "    # Identify numerical columns that are not binary\n",
        "    numerical_cols = [col for col in dataset.columns if col not in binary_cols]\n",
        "\n",
        "    # Scale numerical columns\n",
        "    scaler = StandardScaler()\n",
        "    index = dataset.index # This is really important, we have to preserve the index or else pd.concat will not work correctly\n",
        "    scaled_numerical_data = scaler.fit_transform(dataset[numerical_cols])\n",
        "\n",
        "    # Create DataFrame with scaled numerical data\n",
        "    scaled_numerical_df = pd.DataFrame(scaled_numerical_data, columns=numerical_cols, index=index)\n",
        "\n",
        "    # Combine scaled numerical data with binary columns\n",
        "    scaled_dataset = pd.concat([scaled_numerical_df, dataset[binary_cols]], axis=1)\n",
        "\n",
        "    return scaled_dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vWzwmFGUzcgg"
      },
      "outputs": [],
      "source": [
        "# Isolate features and target columns\n",
        "FEATURES = []\n",
        "TARGET = ['Churn']\n",
        "for col in df.columns:\n",
        "  if col not in TARGET:\n",
        "    FEATURES.append(col)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bt741JB1nObJ"
      },
      "outputs": [],
      "source": [
        "# Since most of our features have binary data we don't want to scale those features\n",
        "non_binaries = {'MonthlyCharges', 'TotalCharges', 'tenure'}\n",
        "binary_features = []\n",
        "for cols in df.columns:\n",
        "  if cols not in non_binaries:\n",
        "    binary_features.append(cols)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nGEwDg34JsMo"
      },
      "outputs": [],
      "source": [
        "def get_X_y(df, FEATURES, TARGET):\n",
        "  X = df[FEATURES]\n",
        "  y = df[TARGET]\n",
        "  return df, X, y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zH--EkiN4mBg"
      },
      "outputs": [],
      "source": [
        "# We will be doing cross validation, so let's split our data\n",
        "# We should not scale our data before doing this though\n",
        "from sklearn.model_selection import train_test_split\n",
        "df, X, y = get_X_y(df, FEATURES=FEATURES, TARGET=TARGET)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PIH_cvrWJ_N4"
      },
      "outputs": [],
      "source": [
        "# Splitting data into 40% for test set and 60% for our training set\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size = 0.4, random_state = 0)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eozZo3NZ4p-6"
      },
      "outputs": [],
      "source": [
        "# Need to remove churn from binary features as it's not in X\n",
        "X_binaries = [col for col in binary_features if col != 'Churn']\n",
        "X_train = selectively_scale_dataset(X_train, binary_cols = X_binaries)\n",
        "X_test = selectively_scale_dataset(X_test, binary_cols = X_binaries)\n",
        "# Don't need to scale y as it's binary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YKfYd38kOaGR"
      },
      "outputs": [],
      "source": [
        "# Transform data to the right shape\n",
        "# In future could put this inside the scaling function...\n",
        "X_train = X_train.values\n",
        "X_test = X_test.values\n",
        "y_train = y_train.values.reshape(-1)\n",
        "y_test = y_test.values.reshape(-1)\n",
        "y = y.values.reshape(-1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wN151J4GMl9u"
      },
      "source": [
        "# SVM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cdGBOe0NM6Yd"
      },
      "outputs": [],
      "source": [
        "from sklearn import svm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rpwiDiPXMX_O"
      },
      "outputs": [],
      "source": [
        "svm_model = svm.SVC(kernel='rbf', C=30, gamma='auto')\n",
        "svm_model = svm_model.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "FXGMIH7HMnNo",
        "outputId": "ae81c875-f5ba-4704-f94f-d326df1d27dd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.83      0.89      0.86      2071\n",
            "           1       0.63      0.50      0.56       747\n",
            "\n",
            "    accuracy                           0.79      2818\n",
            "   macro avg       0.73      0.70      0.71      2818\n",
            "weighted avg       0.78      0.79      0.78      2818\n",
            "\n"
          ]
        }
      ],
      "source": [
        "y_pred = svm_model.predict(X_test)\n",
        "print(classification_report(y_test, y_pred))\n",
        "# Appears as though the model performs decent... but we haven't done cross-validation!\n",
        "# Recall that if they were Churned, that is the '1' case"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "SgjdkmzEMopu"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import cross_val_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hE7PuMJUNcUE",
        "outputId": "19396da2-186d-4052-c60a-b81c90e13b2c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.76 accuracy with a standard deviation of 0.00\n"
          ]
        }
      ],
      "source": [
        "scores = cross_val_score(svm_model, X, y, cv=5)\n",
        "scores\n",
        "print(\"%0.2f accuracy with a standard deviation of %0.2f\" % (scores.mean(), scores.std()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aZ_4vNK81wN0"
      },
      "outputs": [],
      "source": [
        "# Evaluating performance of multiple algorithms and parameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xl6dc_qdf6Nz"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.linear_model import LogisticRegression"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Gp-6dyrV2Dhx"
      },
      "outputs": [],
      "source": [
        "model_params = {\n",
        "    'svm': {\n",
        "        'model': svm.SVC(gamma = 'auto'),\n",
        "        'params': {\n",
        "            'C' : [1],\n",
        "            'kernel': ['rbf', 'linear']\n",
        "        }\n",
        "    },\n",
        "    'random_forest': {\n",
        "        'model': RandomForestClassifier(),\n",
        "        'params': {\n",
        "            'n_estimators': [1]\n",
        "        }\n",
        "    },\n",
        "    'logistic_regression' : {\n",
        "        'model': LogisticRegression(solver='liblinear', multi_class='auto'),\n",
        "        'params': {\n",
        "            'C': [1]\n",
        "        }\n",
        "    }\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZB1fQCBQ2o0-"
      },
      "outputs": [],
      "source": [
        "scores = []\n",
        "\n",
        "for model_name, mp in model_params.items():\n",
        "  clf = GridSearchCV(mp['model'], mp['params'], cv=2, return_train_score=False)\n",
        "  clf.fit(X, y)\n",
        "  scores.append({\n",
        "      'model': model_name,\n",
        "      'best_score': clf.best_score_,\n",
        "      'best_params': clf.best_params_\n",
        "  })"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QNXjX4Lj3IIX"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}